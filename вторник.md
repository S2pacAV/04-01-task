# Шпаргалка: Основные распределения в теории вероятностей и введение в статистику

## Сопоставление теории вероятностей и статистики

**Основные понятия:**
- **Генеральная совокупность (ГС)** - все объекты, которые имеют качества и свойства, интересующие исследователя
- **Выборка** - часть генеральной совокупности элементов, охватываемая экспериментом

> *Ключевое различие*: теория вероятностей описывает генеральную совокупность, а статистика занимается выборкой.

## Распределение данных

**Распределение** - сопоставление значений исследуемых данных с частотой или вероятностью возникновения этих значений.

**Визуализация в Python:**
- `histplot()` - гистограмма
- `barplot()` - столбчатая диаграмма

### Типы данных:
- **Дискретные** - отдельные значения, которые можно подсчитать
  - Примеры: тип автомобиля, цвет, количество людей
- **Непрерывные** - принимают любые значения в каком-либо интервале
  - Примеры: рост, расстояние, возраст

## Функции для работы с распределениями

### 1. Функция вероятности (PMF)
- Применяется для **дискретных** величин
- Возвращает вероятность того, что дискретная случайная величина X примет определённое значение k
- Обозначение: P<sub>X</sub>(k) = P(X = k)
- В Python: `scipy.stats.bernoulli(p=0.6).pmf()`

### 2. Функция плотности вероятности (PDF)
- Применяется для **непрерывных** величин
- Характеризует сравнительную вероятность реализации различных значений случайной переменной
- Обозначение: f<sub>ξ</sub>(x)
- В Python: `scipy.stats.norm(loc=2, scale=0.5).pdf()`

### 3. Функция распределения (CDF)
- Общая для дискретных и непрерывных величин
- Вероятность того, что случайная величина X примет значение, меньшее либо равное х
- Обозначение: F<sub>ξ</sub>(x) = P(ξ ≤ x)
- В Python: `scipy.stats.norm(loc=0, scale=1).cdf(1)`

### 4. Квантиль распределения (PPF)
- Значение, которое заданная случайная величина не превышает с фиксированной вероятностью
- Является обратной функцией к функции распределения
- Если F(x<sub>γ</sub>) = γ, то значение x<sub>γ</sub> = F<sup>-1</sup>(γ) - квантиль уровня γ
- В Python: `scipy.stats.norm(loc=0, scale=1).ppf(0.84)`

## Основные характеристики распределений

### Для генеральной совокупности:
- **Математическое ожидание (среднее)**: E[X], M[X]
  - Для дискретной случайной величины: E[X] = Σ x<sub>i</sub>p<sub>i</sub>
  - Для непрерывной случайной величины: E[X] = ∫ x<sub>i</sub>f(x<sub>i</sub>)

- **Дисперсия**: D[X] = E[(X - E[X])²] = E[X²] - (E[X])²
  - Мера разброса случайной величины

- **Стандартное отклонение**: σ<sub>x</sub> = √D[X]
  - Мера разброса в тех же единицах, что и исходная величина

### Для выборки:
- **Выборочное среднее**: X̄ = (1/n)Σx<sub>i</sub>
  - В Python: `np.mean()`

- **Выборочная дисперсия**: s² = (1/(n-1))Σ(x<sub>i</sub> - X̄)²
  - В Python: `np.var(ddof=1)`

- **Выборочное стандартное отклонение**: s = √s²
  - В Python: `np.std(ddof=1)`

## Центральная предельная теорема (ЦПТ)

Для любой генеральной совокупности с конечным средним μ и дисперсией σ², распределение выборочного среднего X̄, вычисленного по выборке размера n, будет приблизительно нормальным со средним μ и дисперсией σ²/n при большом n.

## Закон больших чисел

При увеличении числа испытаний выборочное среднее случайной величины стремится к истинному математическому ожиданию распределения.

## Основные распределения

### 1. Нормальное распределение
- Обозначение: X ~ N(μ, σ)
- Математическое ожидание: E[X] = μ
- Стандартное отклонение: σ<sub>x</sub> = σ
- **Правило трех сигм**:
  - μ ± σ содержит ~68% значений
  - μ ± 2σ содержит ~95% значений
  - μ ± 3σ содержит ~99.7% значений

### 2. Распределение Бернулли
- Моделирует эксперимент с двумя исходами: успех (с вероятностью p) или неудача (с вероятностью q = 1-p)
- Обозначение: X ~ Be(p)
- Математическое ожидание: E[X] = p
- Стандартное отклонение: σ<sub>x</sub> = √(p(1-p))
- PMF: P<sub>X</sub>(x=k) = p<sup>k</sup>·(1-p)<sup>1-k</sup>

### 3. Биномиальное распределение
- Распределение числа "успехов" в последовательности из n независимых экспериментов с вероятностью успеха p
- Обозначение: Y ~ Bi(n, p)
- Математическое ожидание: E[Y] = n·p
- Стандартное отклонение: σ<sub>Y</sub> = √(n·p·(1-p))
- PMF: P<sub>Y</sub>(k) = (n choose k)·p<sup>k</sup>·(1-p)<sup>n-k</sup>

### 4. Распределение Пуассона
- Моделирует число событий за фиксированное время при постоянной интенсивности λ
- Аппроксимирует биномиальное распределение при большом n и малом p (n·p = λ)
- Обозначение: Y ~ Pois(λ)
- Математическое ожидание: E[Y] = λ
- Стандартное отклонение: σ<sub>Y</sub> = √λ
- PMF: P<sub>Y</sub>(k) = (λ<sup>k</sup>·e<sup>-λ</sup>)/k!
- Примеры: количество опоздавших автобусов, число посетителей сайта
- В Python: `scipy.stats.poisson(lambda)`

### 5. Экспоненциальное распределение
- Моделирует время между независимыми событиями, происходящими с постоянной интенсивностью
- Обозначение: Y ~ exp(λ)
- Математическое ожидание: E[Y] = 1/λ
- Стандартное отклонение: σ<sub>Y</sub> = 1/λ
- PDF: f<sub>Y</sub>(k) = λ·e<sup>-λx</sup>
- Примеры: время между отказами оборудования, время на звонок с клиентом
- В Python: `scipy.stats.expon(lambda)`

## Справка по функциям в SciPy

| Функция | Название | Вопрос | Пример |
|---------|----------|--------|--------|
| pmf | Функция вероятности | Какова вероятность, что X примет значение x? | Какова вероятность выпадения числа 3 при броске кубика? |
| pdf | Функция плотности вероятности | Какова плотность вероятности случайной величины X в точке x? | Какова плотность нормального распределения в точке x = 1? |
| cdf | Функция распределения | Какова вероятность, что X ≤ x? | Какова вероятность того, что время до отказа устройства составит не больше 2 лет? |
| sf | Функция выживания | Какова вероятность, что X > x? | Какова вероятность того, что время до отказа устройства будет больше 2 лет? |
| ppf | Обратная функция распределения | Какое значение X соответствует вероятности p? | Какое значение распределения соответствует 95%-му процентилю? |

> **Примечание**: Функция выживания = 1 - Функция распределения
